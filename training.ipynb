{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dcbbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Add current directory to path for imports\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import utility functions\n",
    "from utils import (\n",
    "    # Data preparation\n",
    "    prepare_data_for_model,\n",
    "    prepare_data_for_transformer,  # Backward compatibility\n",
    "    \n",
    "    # Model creation\n",
    "    create_model,\n",
    "    count_parameters,\n",
    "    DEFAULT_MODEL_CONFIGS,\n",
    "    \n",
    "    # Training functions\n",
    "    setup_training,\n",
    "    create_checkpoint_dir,\n",
    "    save_checkpoint,\n",
    "    train_single_epoch,\n",
    "    evaluate_model,\n",
    "    train_water_level_model,\n",
    "    train_transformer_flood_detection,  # Backward compatibility\n",
    "    \n",
    "    # Checkpoint management\n",
    "    load_checkpoint,\n",
    "    list_checkpoints,\n",
    "    resume_training,\n",
    "    \n",
    "    # Prediction and evaluation\n",
    "    batched_inference,\n",
    "    create_continuous_predictions,\n",
    "    calculate_metrics,\n",
    "    \n",
    "    # Visualization\n",
    "    plot_training_history,\n",
    "    plot_predictions,\n",
    "    plot_error_analysis\n",
    ")\n",
    "\n",
    "# Import model classes directly for convenience\n",
    "from models.transformer import TransformerWaterLevelPrediction\n",
    "from models.lstm import LSTMFloodDetection\n",
    "\n",
    "print(\"Utilities and models imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i8t2lgmz68h",
   "metadata": {},
   "source": [
    "# Water Level Prediction Training Notebook\n",
    "\n",
    "This notebook provides a clean interface for training water level prediction models using either Transformer or LSTM architectures.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. **Import utilities and set device** (Cell 1)\n",
    "2. **Configure model type** (Cell 3) - Set `MODEL_TYPE = 'transformer'` or `MODEL_TYPE = 'lstm'`\n",
    "3. **Run training** (Cell 4)\n",
    "4. **Visualize results** (Cells 5-8)\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Easy model switching**: Just change `MODEL_TYPE` variable\n",
    "- **Automated data preparation**: Handles normalization and sequence creation\n",
    "- **Memory-efficient training**: Batched processing with GPU memory management\n",
    "- **Comprehensive evaluation**: Multiple visualization and metric options\n",
    "- **Checkpoint management**: Automatic saving and easy model loading\n",
    "\n",
    "## Available Models\n",
    "\n",
    "- **Transformer**: Multi-head attention-based model for sequence prediction\n",
    "- **LSTM**: Bidirectional LSTM with multiple layers\n",
    "\n",
    "All utility functions are now in `utils.py` for cleaner code organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeef495",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c091eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MODEL CONFIGURATION =====\n",
    "# Choose model type: 'transformer' or 'lstm'\n",
    "MODEL_TYPE = 'transformer'  # Change this to 'lstm' to use LSTM model\n",
    "\n",
    "# ===== TRAINING HYPERPARAMETERS =====\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "evaluation_frequency = 5  # Evaluate every 5 epochs\n",
    "\n",
    "# ===== COMMON MODEL PARAMETERS =====\n",
    "input_size = 1  # Single feature (water level)\n",
    "seq_len = 3*24*10  # 720 time steps\n",
    "prediction_horizon = 24*10  # Predicting 240 steps ahead (24 hours)\n",
    "output_size = prediction_horizon  # Predicting multiple future values\n",
    "\n",
    "# ===== MODEL-SPECIFIC CONFIGURATIONS =====\n",
    "# You can override default configurations here\n",
    "custom_model_configs = {\n",
    "    'transformer': {\n",
    "        'hidden_dim': 128,\n",
    "        'num_heads': 8,\n",
    "        'dim_feedforward': 512,\n",
    "        'num_layers_enc': 4,\n",
    "        'num_layers_dec': 4,\n",
    "        'dropout': 0.1,\n",
    "    },\n",
    "    'lstm': {\n",
    "        'hidden_dim': 128,\n",
    "        'num_layers': 3,\n",
    "        'dropout': 0.1,\n",
    "        'bidirectional': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load data - use one of the parquet files for faster loading\n",
    "try:\n",
    "    # Try to load from parquet first (much faster)\n",
    "    df = pd.read_parquet('data/1836026195.parquet')\n",
    "    print(f\"Loaded data from parquet: {df.shape}\")\n",
    "except:\n",
    "    print(\"Parquet file not found. Please run the data loading cells first.\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"Data range: {df['collect_time'].min()} to {df['collect_time'].max()}\")\n",
    "    print(f\"Data shape: {df.shape}\")\n",
    "    \n",
    "    # Prepare data for multi-step prediction\n",
    "    X_train_src, X_test_src, y_train_tgt, y_test_tgt, scaler = prepare_data_for_model(\n",
    "        df, \n",
    "        seq_len=seq_len, \n",
    "        test_size=0.2, \n",
    "        prediction_horizon=prediction_horizon\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTarget shapes after data preparation:\")\n",
    "    print(f\"y_train_tgt: {y_train_tgt.shape}\")\n",
    "    print(f\"y_test_tgt: {y_test_tgt.shape}\")\n",
    "\n",
    "    # Create model using factory function\n",
    "    model = create_model(\n",
    "        MODEL_TYPE,\n",
    "        input_size=input_size,\n",
    "        output_size=output_size,\n",
    "        device=device,\n",
    "        seq_len=seq_len,\n",
    "        custom_config=custom_model_configs.get(MODEL_TYPE)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    param_stats = count_parameters(model)\n",
    "    \n",
    "    print(f\"\\nModel Summary ({MODEL_TYPE.upper()}):\")\n",
    "    print(f\"Total parameters: {param_stats['total']:,}\")\n",
    "    print(f\"Trainable parameters: {param_stats['trainable']:,}\")\n",
    "    print(f\"Model size: {param_stats['size_mb']:.2f} MB\")\n",
    "    print(f\"\\nReady to train {MODEL_TYPE} model! Run the next cell to start training.\")\n",
    "else:\n",
    "    print(\"Please load data first by running the earlier cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef20c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute training using the modular training function\n",
    "train_losses, test_losses = train_water_level_model(\n",
    "    model, X_train_src, y_train_tgt, X_test_src, y_test_tgt,\n",
    "    model_type=MODEL_TYPE,  # Uses the MODEL_TYPE defined in configuration\n",
    "    epochs=epochs,\n",
    "    lr=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    evaluation_frequency=evaluation_frequency,\n",
    "    device=device\n",
    ")\n",
    "print(f\"\\nTraining completed for {MODEL_TYPE} model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history using utility function\n",
    "plot_training_history(train_losses, test_losses, evaluation_frequency=evaluation_frequency)\n",
    "\n",
    "print(f\"Training epochs: {len(train_losses)} (all epochs)\")\n",
    "print(f\"Test evaluations: {len(test_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbef4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "model.eval()\n",
    "\n",
    "# Use batched inference for memory efficiency\n",
    "print(\"Running batched inference...\")\n",
    "train_pred = batched_inference(model, X_train_src, batch_size=batch_size, device=device)\n",
    "test_pred = batched_inference(model, X_test_src, batch_size=batch_size, device=device)\n",
    "\n",
    "print(f\"Prediction shapes:\")\n",
    "print(f\"train_pred: {train_pred.shape}\")\n",
    "print(f\"test_pred: {test_pred.shape}\")\n",
    "\n",
    "# For multi-step predictions, we need to flatten for inverse transform\n",
    "if y_train_tgt.dim() == 3:\n",
    "    y_train_flat = y_train_tgt.squeeze(-1)\n",
    "    y_test_flat = y_test_tgt.squeeze(-1)\n",
    "else:\n",
    "    y_train_flat = y_train_tgt\n",
    "    y_test_flat = y_test_tgt\n",
    "\n",
    "# Reshape for inverse transform\n",
    "train_pred_reshaped = train_pred.cpu().numpy().reshape(-1, 1)\n",
    "test_pred_reshaped = test_pred.cpu().numpy().reshape(-1, 1)\n",
    "y_train_reshaped = y_train_flat.cpu().numpy().reshape(-1, 1)\n",
    "y_test_reshaped = y_test_flat.cpu().numpy().reshape(-1, 1)\n",
    "\n",
    "# Inverse transform predictions\n",
    "train_pred_unscaled = scaler.inverse_transform(train_pred_reshaped).flatten()\n",
    "test_pred_unscaled = scaler.inverse_transform(test_pred_reshaped).flatten()\n",
    "y_train_unscaled = scaler.inverse_transform(y_train_reshaped).flatten()\n",
    "y_test_unscaled = scaler.inverse_transform(y_test_reshaped).flatten()\n",
    "\n",
    "# Extract first-step predictions for cleaner visualization\n",
    "first_step_pred = test_pred[:, 0].cpu().numpy()\n",
    "first_step_true = y_test_flat[:, 0].cpu().numpy()\n",
    "first_pred_unscaled = scaler.inverse_transform(first_step_pred.reshape(-1, 1)).flatten()\n",
    "first_true_unscaled = scaler.inverse_transform(first_step_true.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Plot predictions\n",
    "plot_predictions(first_pred_unscaled, first_true_unscaled, time_step=6/60, n_points=200)\n",
    "\n",
    "# Calculate and display metrics\n",
    "metrics = calculate_metrics(first_pred_unscaled, first_true_unscaled)\n",
    "print(f\"\\nFirst-Step Prediction Metrics:\")\n",
    "print(f\"MSE:  {metrics['mse']:.6f} ftÂ²\")\n",
    "print(f\"RMSE: {metrics['rmse']:.6f} ft\")\n",
    "print(f\"MAE:  {metrics['mae']:.6f} ft\")\n",
    "print(f\"RÂ²:   {metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8090d584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display comprehensive training results summary\n",
    "print(\"=\" * 80)\n",
    "print(f\"TRAINING RESULTS SUMMARY - {MODEL_TYPE.upper()} MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Training Setup:\")\n",
    "print(f\"  Model Type:          {MODEL_TYPE}\")\n",
    "print(f\"  Epochs trained:      {len(train_losses)}\")\n",
    "print(f\"  Evaluations run:     {len(test_losses)}\")\n",
    "print(f\"  Prediction Horizon:  {prediction_horizon} steps ({prediction_horizon * 6 / 60:.1f} hours)\")\n",
    "print(f\"  Model Parameters:    {param_stats['total']:,}\")\n",
    "print(f\"  Model Size:          {param_stats['size_mb']:.2f} MB\")\n",
    "print()\n",
    "print(f\"ðŸ“Š PERFORMANCE METRICS (First-Step Predictions):\")\n",
    "print(f\"  Predictions:         {len(first_pred_unscaled):,} values\")\n",
    "print(f\"  MSE:                 {metrics['mse']:.6f} ftÂ²\")\n",
    "print(f\"  RMSE:                {metrics['rmse']:.6f} ft\")\n",
    "print(f\"  MAE:                 {metrics['mae']:.6f} ft\")\n",
    "print(f\"  RÂ² Score:            {metrics['r2']:.4f}\")\n",
    "print()\n",
    "print(f\"ðŸ’¡ NOTE: First-step predictions shown for clean visualization.\")\n",
    "print(f\"   The model actually predicts {prediction_horizon} steps ahead.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb84705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create continuous predictions and perform error analysis\n",
    "if 'model' in locals() and 'X_test_src' in locals() and 'y_test_tgt' in locals():\n",
    "    print(\"Creating continuous predictions from non-overlapping sequences...\")\n",
    "    \n",
    "    # Get continuous predictions\n",
    "    continuous_results = create_continuous_predictions(\n",
    "        model, X_test_src, y_test_tgt, scaler, \n",
    "        seq_len=seq_len, \n",
    "        prediction_horizon=prediction_horizon,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    if continuous_results is not None:\n",
    "        pred_unscaled, true_unscaled = continuous_results\n",
    "        \n",
    "        # Plot error analysis\n",
    "        error_metrics = plot_error_analysis(\n",
    "            pred_unscaled, \n",
    "            true_unscaled, \n",
    "            prediction_horizon=prediction_horizon\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… Continuous Prediction Analysis Complete!\")\n",
    "        print(f\"Total predictions: {len(pred_unscaled):,}\")\n",
    "        print(f\"Time coverage: {len(pred_unscaled) * 6/60:.1f} hours\")\n",
    "        print(f\"Non-overlapping sequences: {len(pred_unscaled) // prediction_horizon:,}\")\n",
    "else:\n",
    "    print(\"Please run the training cells first to create the model and test data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8by5vjumxy",
   "metadata": {},
   "source": [
    "## How to Switch Between Models\n",
    "\n",
    "To switch between transformer and LSTM models:\n",
    "\n",
    "1. **Change the MODEL_TYPE variable** in the configuration cell:\n",
    "   - `MODEL_TYPE = 'transformer'` for Transformer model\n",
    "   - `MODEL_TYPE = 'lstm'` for LSTM model\n",
    "\n",
    "2. **Adjust model-specific parameters** in the `model_configs` dictionary if needed:\n",
    "   - Transformer: `num_heads`, `dim_feedforward`, `num_layers_enc`, `num_layers_dec`\n",
    "   - LSTM: `num_layers`, `bidirectional`\n",
    "\n",
    "3. **Run the cells** in order:\n",
    "   - Configuration cell (creates the model)\n",
    "   - Training cell (trains the model)\n",
    "   - Evaluation cells (analyze results)\n",
    "\n",
    "4. **Model checkpoints** are saved in separate directories:\n",
    "   - `model_checkpoints/transformer/` for transformer models\n",
    "   - `model_checkpoints/lstm/` for LSTM models\n",
    "\n",
    "### Example: Quick Model Comparison\n",
    "\n",
    "```python\n",
    "# To compare both models:\n",
    "# 1. Train transformer: Set MODEL_TYPE = 'transformer', run training\n",
    "# 2. Train LSTM: Set MODEL_TYPE = 'lstm', run training\n",
    "# 3. Use list_checkpoints() to see all saved models\n",
    "# 4. Load and compare using load_checkpoint()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nll40u7cl1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Quick model comparison workflow\n",
    "# Uncomment and run this cell to compare models\n",
    "\n",
    "\"\"\"\n",
    "# Step 1: Train Transformer Model\n",
    "MODEL_TYPE = 'transformer'\n",
    "transformer_model = create_model(MODEL_TYPE).to(device)\n",
    "print(\"Training Transformer model...\")\n",
    "transformer_losses = train_water_level_model(\n",
    "    transformer_model, X_train_src, y_train_tgt, X_test_src, y_test_tgt,\n",
    "    model_type=MODEL_TYPE,\n",
    "    epochs=5,  # Use fewer epochs for quick comparison\n",
    "    lr=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    evaluation_frequency=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Step 2: Train LSTM Model\n",
    "MODEL_TYPE = 'lstm'\n",
    "lstm_model = create_model(MODEL_TYPE).to(device)\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "lstm_losses = train_water_level_model(\n",
    "    lstm_model, X_train_src, y_train_tgt, X_test_src, y_test_tgt,\n",
    "    model_type=MODEL_TYPE,\n",
    "    epochs=5,  # Use fewer epochs for quick comparison\n",
    "    lr=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    evaluation_frequency=1,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Step 3: Compare Results\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Transformer - Final Test Loss: {transformer_losses[1][-1]:.6f}\")\n",
    "print(f\"LSTM - Final Test Loss: {lstm_losses[1][-1]:.6f}\")\n",
    "\n",
    "# Step 4: List all checkpoints\n",
    "print(\"\\nAll saved checkpoints:\")\n",
    "all_checkpoints = list_checkpoints()\n",
    "\"\"\"\n",
    "\n",
    "print(\"Uncomment the code above to run a quick comparison between models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bx7iamtmzt6",
   "metadata": {},
   "source": [
    "## Checkpoint Management\n",
    "\n",
    "Use these utilities to manage saved models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nmajqggrqf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all available checkpoints\n",
    "print(\"Available checkpoints:\")\n",
    "all_checkpoints = list_checkpoints()\n",
    "\n",
    "# List checkpoints for a specific model type\n",
    "print(\"\\nTransformer checkpoints:\")\n",
    "transformer_checkpoints = list_checkpoints(model_type='transformer')\n",
    "\n",
    "print(\"\\nLSTM checkpoints:\")\n",
    "lstm_checkpoints = list_checkpoints(model_type='lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6zcr9oi7jph",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load a checkpoint\n",
    "# Uncomment and modify the path to load a specific checkpoint\n",
    "\n",
    "\"\"\"\n",
    "# Load best model\n",
    "best_model_path = f'model_checkpoints/{MODEL_TYPE}/best_{MODEL_TYPE}_model.pth'\n",
    "loaded_model, checkpoint_info = load_checkpoint(best_model_path, device=device)\n",
    "\n",
    "# Or resume training from a checkpoint\n",
    "model, total_train_losses, total_test_losses = resume_training(\n",
    "    checkpoint_path=best_model_path,\n",
    "    X_train=X_train_src,\n",
    "    y_train=y_train_tgt,\n",
    "    X_test=X_test_src,\n",
    "    y_test=y_test_tgt,\n",
    "    additional_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=32,\n",
    "    evaluation_frequency=5,\n",
    "    device=device\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "print(\"Checkpoint management utilities are ready to use!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
